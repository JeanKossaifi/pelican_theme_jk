<div class="box">
	<nav class="tile is-parent">
		<div class="tile is-5">
			<figure class="image project-img">
				<img src="{{ SITEURL }}/images/TensorLy_logo.png" alt="Image">
			</figure>
		</div>
		<div class="tile is-7">
				<div class="content">
					<h4 class="title project-title is-4"><a href="https://tensorly.github.io/dev/">TensorLy</a></h4>
					<p>
					Creator and lead developer of TensorLy, a library for tensor methods in Python. 
					</p>
					<p>
					TensorLy is a fast and simple Python library for tensor learning. It builds on top of NumPy, SciPy and allows for fast and straightforward tensor decomposition, tensor learning and tensor algebra.
					<p>
					Its flexible backend system allows to run operations transparently on GPU or Multi-Machines using PyTorch or MXNet, and to combine Tensor Methods with Deep-Learning
					</p>
				</div>
		</div>
	</nav>
	<nav class="level">
		<div class="level-left">
		</div>
		<div class="level-right">
		<div class="level-item">
		<a class="button" href="https://tensorly.github.io/dev/">
			Website
		</a>
		</div>
		<div class="level-item">
		<a class="button" href="https://github.com/tensorly/tensorly">
			Github
		</a>
		</div>
		<div class="level-item">
		<a class="button" href="https://github.com/JeanKossaifi/tensorly-notebooks">
			Notebooks
		</a>
		</div>
		</div>
	</nav>
</div>


<div class="box">
	<nav class="tile is-parent">
		<div class="tile is-5">
			<figure class="image project-img">
				<img src="{{ SITEURL }}/images/afewva.png" alt="Image">
			</figure>
		</div>
		<div class="tile is-7">
				<div class="content">
					<h4 class="title project-title is-4"><a href="https://ibug.doc.ic.ac.uk/resources/afew-va-database/">AFEW-VA database</a></h4>
					<p>
					Author of the AFEW-VA database for Valence and Arousal estimation in-the-wild.
					</p>
					<p>
					The AFEW-VA databaset is a collection of highly accurate per-frame annotations levels of valence and arousal, along with per-frame annotations of 68 facial landmarks for 600 challenging video clips. These clips are extracted from feature films and were also annotated in terms of discrete emotion categories in the form of the AFEW database (that can be obtained there).
					</p>
				</div>
		</div>
	</nav>
	<nav class="level is-link">
		<div class="level-left">
		</div>
		<div class="level-right">
		<div class="level-item">
		<a class="button" href="https://tensorly.github.io/dev/">
			Database
		</a>
		</div>
		</div>
	</nav>
</div>


<div class="box">
	<nav class="tile is-parent">
		<div class="tile is-5">
			<figure class="image project-img">
				<img src="{{ SITEURL }}/images/annotation_tool.png" alt="Image">
			</figure>
		</div>
		<div class="tile is-7">
				<div class="content">
					<h4 class="title project-title is-4"><a href="https://github.com/JeanKossaifi/valence_arousal_annotator">Online annotation tool</a></h4>
					<p>
					Valence/Arousal Online Annotation Tool
					</p>
					<p>
					This tool, written in Python as a Flask application backed with a MongoDB, allows any number people to annotate video clips per-frame, for valence and arousal, remotely. In addition it can be easily extended to handle more annotations (e.g. discrete emotions).
					</p>
				</div>
		</div>
	</nav>
	<nav class="level is-link">
	<div class="level-left">
	</div>

	<div class="level-right">
		<div class="level-item">
		<a class="button" href="https://github.com/JeanKossaifi/valence_arousal_annotator">
			Code
		</a>
		</div>
		<div class="level-item">
		<a class="button" href="https://github.com/JeanKossaifi/valence_arousal_annotator/wiki">
			Wiki
		</a>
		</div>
	</div>
	</nav>
</div>


